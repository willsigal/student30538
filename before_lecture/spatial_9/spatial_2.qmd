---
title: "Spatial II"
author: "Peter Ganong and Maggie Shi"
date: today
date-format: long
execute: 
    echo: true
format:
    beamer:
        toc: true
        fig-height: 2.5
        include-in-header: header_pagenrs.tex
include-before-body:
  text: |
    \RecustomVerbatimEnvironment{verbatim}{Verbatim}{
      showspaces = false,
      showtabs = false,
      breaksymbolleft={},
      breaklines
    }
    
---

# Introduction to data structures in geopandas (6.2)

## Geopandas roadmap

In practice, we won't be coding our geodata by hand... Instead we are going to use shapefiles!

```{python}
import geopandas as gpd
```


Roadmap

-   Vocabulary
-   File formats
-   Read in data
-   Preview data

## Define vocabulary

Vocabulary

-   A `GeoDataFrame` is basically like a `pandas.DataFrame` that contains dedicated columns for storing geometries.
    - We will start with examples with a single column and later teach you how to use more than one column
-   That column is called a `GeoSeries`. This can be any of data types (point, line, polygon) from the prior section. All of the methods you saw in the last section can also be used on a `GeoSeries`


## File format I: Shapefile

-   consists of at least three files `.shp` has feature geometrics, `.shx` has a positional index, `.dbf` has attribute information
-   Usually also have `.prj` which describes the Coordinate Reference System (CRS)
-   When you read in `map.shp` it automatically reads the rest of them as well to give you proper GeoDataFrame composed of geometry, attributes and projection.

## File format II: GeoPackage

-   single file `.gpkg`
-   Supports both raster and vector data
-   Efficiently decodable by software, particularly in mobile devices

GeoPackage is more modern, but you will encounter shapefiles everywhere you look so good to be familiar with it.

## Coordinate Reference Systems
- Coordinate Reference System (CRS) is a combination of:
    - "Datum": origin of latitude and longitude 
    - "Project": representation of curved surface onto flat map
- Most common CRS: WGS84 (used for GPS)
- All coordinates are consistent *within* a CRS, but not always *across* CRS's
- Different CRS's suit different needs
    - optimized for local vs. global accuracy
    - different approaches to approx. shape of the earth
    - distance is measured in different units: degrees, miles, meters
- Each system is associated with a unique *EPSG code*. Searchable on [https://epsg.io](https://epsg.io)
    - (Aside: EPSG stands for European Petroleum Survey Group)
    - These codes are used to convert one CRS into another


## Reading a Shapefile `.shp`

```{python}
#in same dir:  `.shx` and `.dbf`
filepath = "data/shp/austin_pop_2019.shp"
data = gpd.read_file(filepath)
```

## Reading a GeoPackage `gpkg`

```{python}
filepath = "data/austin_pop_2019.gpkg"
data = gpd.read_file(filepath)
type(data)
```

## Previewing a `GeoDataFrame`

```{python}
data.head()
```



## Previewing a `GeoSeries`

```{python, fig-align="center" height=70%}
#| fig-height: 3
data.plot()
```

Discussion question: Why isn't it enough to just to `head()`?


## Geopandas summary

-   `GeoDataFrame` and `GeoSeries` are the counterparts of `pandas.DataFrame` and `pandas.Series`
-   `.shp` and `.gpkg` are two ways of storing geo data
-   Always plot your map before you do anything else

# Geometries in geopandas (6.2)

## geometries: roadmap

-   methods applied to `GeoSeries`
-   my first choropleth


## `GeoSeries`

```{python}
type(data["geometry"])
```


## `head()`

```{python}
data["geometry"].head()
```

## calculate area (in km\^2)

```{python}
data["geometry"].area
```

## add column to data frame

```{python}
#data.area is just a shorthand for data.geometry.area
data["area_km2"] = data.area / 1000000
data.head()
```

## my first choropleth

```{python}
data.plot(column="area_km2", legend=True)
```

Why is this a nearly useless set of colors?

## geometries: summary

-   can do all the same operations on a `GeoSeries` that you would do on any other polygon, like `Area`
-   `data.plot(column="var")` draws a choropleth map with shading corresponding to the highlighted variable


# Common geometric operations (6.3)

## common geometric operations: roadmap

* load and explore data
* methods
    * centroid
    * bounding box
    * buffer
    * dissolve
    * spatial join
* do-pair-share

## Austin, continued

(The textbook uses a slightly different file here, unclear why.)
```{python}
filepath = "data/austin_pop_density_2019.gpkg"
data = gpd.read_file(filepath)
```

## explore the data I
```{python}
data.head()
```

## explore the data II
```{python}
type(data["geometry"].values[0])
```

## explore the data III
```{python out-height = 1.5}
import matplotlib.pyplot as plt
data.plot(facecolor="none", linewidth=0.2)
plt.axis("off")
plt.show()
```

- Import `matplotlib.pyplot` to access additional plotting options (e.g., x and y labels, title)
- We turn the axis off because the WKT is not particularly informative


## explore the data IV
```{python out-height = 1.5}
data.plot(column="pop_density_km2")
plt.axis("off")
plt.show()
```

- `facecolor` (or `fc` or `color`) defines a uniform color across all geometries
- whereas `columns` generates colors based on the underlying values 

## methods: centroid I

What it is: arithmetic mean position of all the points in a polygon

Sample use case: measuring distance between center of each multipolygon

```{python}
data["geometry"].centroid.head()
```

## methods: centroid II
```{python}
data.centroid.plot(markersize=1)
plt.axis("off")
plt.show()
```

## methods: bounding box definition

What it is: the tightest possible rectangle around a shape, capturing all of its points within this rectangle. 

Sample use case: filtering a larger spatial dataset to subset of interest

```{python}
data["centroid"] = data.centroid

data[['tract', 'centroid', 'geometry']]
data.set_geometry('centroid')
data['geometry'].area
```
## methods: bounding box for each polygon I

```{python}
data.envelope.head()
```

## methods: bounding box for each polygon II
```{python}
data.envelope.plot()
```


## methods: bounding box for whole data I
```{python}
data.total_bounds
```

## methods: bounding box for whole data II
Flashback to section 6.1
```{python}
from shapely import Point, Polygon
point1 = Point(data.total_bounds[0], data.total_bounds[1])
point2 = Point(data.total_bounds[2], data.total_bounds[1])
point3 = Point(data.total_bounds[2], data.total_bounds[3])
point4 = Point(data.total_bounds[0], data.total_bounds[3])
poly = Polygon([point1, point2, point3, point4])
#poly
```
- *Note*: the order in which you put these points together matters, and you'll get all sorts of interesting shapes with different orders!


## methods: buffer I

What it is: shape representing all points that are less than a certain distance from the original shape

Sample use case: how many stores or parks near a neighborhood

## methods: buffer II

```{python}
data.buffer(1000).plot(edgecolor="white") #1000 meters
plt.axis("off")
plt.show()
```

## methods: dissolve I

What it is: combining geometries into coarser spatial units based on some attributes. 

Sample use case: construct the geometries that you want to serve with public transit

```{python}
# Create a new column and add a constant value
data["dense"] = 0

# Filter rows with above average pop density and update the column dense
data.loc[data["pop_density_km2"] > data["pop_density_km2"].mean(), "dense"] = 1
data.dense.value_counts()
```


## methods: dissolve II
```{python}
dissolved = data[["pop2019", "area_km2", "dense", "geometry"]].dissolve(
    by="dense", aggfunc="sum"
)
#aggregation step set index to "dense", reset to default
dissolved = dissolved.reset_index()
dissolved

dissolved['geometry']
```

- Aggregating alters the way the data is indexed and makes the grouping variable the index
- We need to reset it in order to plot, since some plotting libraries expect data to be indexed in a specific way


## methods: dissolve III
```{python}
dissolved.plot(column="dense")
plt.axis("off")
plt.show()
```

Discussion Question: is this a good map? What can we do to improve it?

## methods: spatial join

Spatial join: find the closest neighbor.

(Contrived) example: Join Austin tracts to themselves. How many tracts should we expect to get?

```{python}
data_for_join = data[["tract", "geometry"]]
print("N tracts " + str(len(data_for_join)))
join_to_self = gpd.sjoin_nearest(data_for_join, data_for_join, how='inner', distance_col="distance")
```


## methods: spatial join II


```{python}
print("N tracts w closest neighbor " + str(len(join_to_self)))
join_to_self.head(4)
```


## common geometric operations: summary

* methods 
    * centroid computes arithmetic mean of points in the polygon
    * bounding box expands polygon in a rectangle
    * buffer expands polygon in every direction
    * dissolve combines several polygons
    * spatial join finds nearest neighbor
* do-pair-share

## do pair share

Goal: Create and plot a 500m buffer zone around the dense areas in Austin.

Steps

1. From the `dissolved` `GeoDataFrame`, get the polygon for the dense areas
2. Create a new geometry object called `geo`, which is the dense areas with a 500m buffer
3. `geo.plot()` 

```{python}
data['dense']
```

```{python}
austin = data.plot(color = 'grey')

```


```{python}

austin = data.plot(color = 'grey')
geo = dissolved[dissolved['dense'] == 1]

geo = geo.reset_index()

geo = geo.buffer(500)

geo.plot(ax = austin, alpha = .5)

```



After you are done, here are some cosmetic suggestions:

* Start with a grey plot of all of the Austin boundaries: `austin = data.plot(color="grey")`
* Make your buffer transparent
* Putting it all together `geo.plot(ax = austin, alpha=0.5)`
    - This plots the `geo` object with 50% transparency, on top of axes based on the `austin` object


